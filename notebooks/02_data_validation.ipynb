{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# NFL Data Validation & Quality Check\n",
        "\n",
        "This notebook validates our data sources and identifies any gaps before building ML models.\n",
        "\n",
        "## Goals:\n",
        "1. Check data availability and quality\n",
        "2. Identify missing data for ML features\n",
        "3. Validate data completeness for predictions\n",
        "4. Document data gaps and next steps\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "import nfl_data_py as nfl\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set up plotting\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data Source Validation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== DATA SOURCE VALIDATION ===\n",
            "Checking data for seasons: [2020, 2021, 2022, 2023, 2024]\n",
            "\n",
            "‚úÖ schedules: 1408 rows, 46 columns\n",
            "Downcasting floats.\n",
            "‚úÖ weekly_data: 28026 rows, 53 columns\n",
            "2020 done.\n",
            "2021 done.\n",
            "2022 done.\n",
            "2023 done.\n",
            "2024 done.\n",
            "Downcasting floats.\n",
            "‚úÖ play_by_play: 246218 rows, 397 columns\n",
            "‚úÖ seasonal_rosters: 15464 rows, 37 columns\n",
            "‚úÖ next_gen_passing: 3026 rows, 29 columns\n",
            "‚úÖ next_gen_rushing: 3055 rows, 22 columns\n",
            "‚úÖ next_gen_receiving: 7469 rows, 23 columns\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Define seasons to check\n",
        "seasons = [2020, 2021, 2022, 2023, 2024]\n",
        "\n",
        "print(\"=== DATA SOURCE VALIDATION ===\")\n",
        "print(f\"Checking data for seasons: {seasons}\")\n",
        "print()\n",
        "\n",
        "# Test each data source\n",
        "data_sources = {\n",
        "    'schedules': nfl.import_schedules,\n",
        "    'weekly_data': nfl.import_weekly_data,\n",
        "    'play_by_play': lambda years: nfl.import_pbp_data(years, cache=False),\n",
        "    'seasonal_rosters': nfl.import_seasonal_rosters,\n",
        "    'next_gen_passing': lambda years: nfl.import_ngs_data(stat_type='passing', years=years),\n",
        "    'next_gen_rushing': lambda years: nfl.import_ngs_data(stat_type='rushing', years=years),\n",
        "    'next_gen_receiving': lambda years: nfl.import_ngs_data(stat_type='receiving', years=years)\n",
        "}\n",
        "\n",
        "data_availability = {}\n",
        "\n",
        "for source_name, source_func in data_sources.items():\n",
        "    try:\n",
        "        data = source_func(seasons)\n",
        "        data_availability[source_name] = {\n",
        "            'status': 'SUCCESS',\n",
        "            'rows': len(data),\n",
        "            'columns': len(data.columns),\n",
        "            'date_range': f\"{data.get('season', pd.Series()).min()}-{data.get('season', pd.Series()).max()}\" if 'season' in data.columns else 'N/A'\n",
        "        }\n",
        "        print(f\"‚úÖ {source_name}: {len(data)} rows, {len(data.columns)} columns\")\n",
        "    except Exception as e:\n",
        "        data_availability[source_name] = {\n",
        "            'status': 'FAILED',\n",
        "            'error': str(e)\n",
        "        }\n",
        "        print(f\"‚ùå {source_name}: {str(e)}\")\n",
        "\n",
        "print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. ML Feature Availability Check\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== ML FEATURE AVAILABILITY ===\n",
            "Downcasting floats.\n",
            "2020 done.\n",
            "2021 done.\n",
            "2022 done.\n",
            "2023 done.\n",
            "2024 done.\n",
            "Downcasting floats.\n",
            "‚úÖ Loaded 1408 games, 28026 player stats, 246218 plays, 15464 roster records\n",
            "\n",
            "GAME OUTCOME:\n",
            "  Description: Predict which team wins a game\n",
            "  ‚úÖ Available: ['home_team', 'away_team', 'home_score', 'away_score', 'weather', 'stadium', 'season', 'week']\n",
            "  ‚ùå Missing: []\n",
            "  üìä Coverage: 100.0%\n",
            "\n",
            "PLAYER FANTASY POINTS:\n",
            "  Description: Predict player fantasy performance\n",
            "  ‚úÖ Available: ['player_id', 'position', 'passing_yards', 'rushing_yards', 'receiving_yards', 'interceptions']\n",
            "  ‚ùå Missing: ['touchdowns', 'fumbles']\n",
            "  üìä Coverage: 75.0%\n",
            "\n",
            "TEAM PERFORMANCE:\n",
            "  Description: Predict team offensive/defensive performance\n",
            "  ‚úÖ Available: ['team', 'total_yards (derivable from PBP)', 'turnovers (derivable from PBP)', 'time_of_possession (derivable from PBP)', 'third_down_conversion (derivable from PBP)', 'red_zone_efficiency (derivable from PBP)', 'epa']\n",
            "  ‚ùå Missing: []\n",
            "  üìä Coverage: 100.0%\n"
          ]
        }
      ],
      "source": [
        "print(\"=== ML FEATURE AVAILABILITY ===\")\n",
        "\n",
        "# Load core datasets first\n",
        "try:\n",
        "    games = nfl.import_schedules(seasons)\n",
        "    player_stats = nfl.import_weekly_data(seasons)\n",
        "    pbp_data = nfl.import_pbp_data(seasons, cache=False)\n",
        "    rosters = nfl.import_seasonal_rosters(seasons)\n",
        "    print(f\"‚úÖ Loaded {len(games)} games, {len(player_stats)} player stats, {len(pbp_data)} plays, {len(rosters)} roster records\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error loading data: {e}\")\n",
        "    games = pd.DataFrame()\n",
        "    player_stats = pd.DataFrame()\n",
        "    pbp_data = pd.DataFrame()\n",
        "    rosters = pd.DataFrame()\n",
        "\n",
        "# Define features needed for different prediction tasks\n",
        "prediction_tasks = {\n",
        "    'game_outcome': {\n",
        "        'required_features': [\n",
        "            'home_team', 'away_team', 'home_score', 'away_score',\n",
        "            'weather', 'stadium', 'season', 'week'\n",
        "        ],\n",
        "        'description': 'Predict which team wins a game'\n",
        "    },\n",
        "    'player_fantasy_points': {\n",
        "        'required_features': [\n",
        "            'player_id', 'position', 'passing_yards', 'rushing_yards',\n",
        "            'receiving_yards', 'touchdowns', 'fumbles', 'interceptions'\n",
        "        ],\n",
        "        'description': 'Predict player fantasy performance'\n",
        "    },\n",
        "    'team_performance': {\n",
        "        'required_features': [\n",
        "            'team', 'total_yards', 'turnovers', 'time_of_possession',\n",
        "            'third_down_conversion', 'red_zone_efficiency', 'epa'\n",
        "        ],\n",
        "        'description': 'Predict team offensive/defensive performance',\n",
        "        'derivable_from_pbp': [\n",
        "            'total_yards', 'turnovers', 'time_of_possession',\n",
        "            'third_down_conversion', 'red_zone_efficiency', 'epa'\n",
        "        ]\n",
        "    }\n",
        "}\n",
        "\n",
        "feature_availability = {}\n",
        "\n",
        "for task, config in prediction_tasks.items():\n",
        "    print(f\"\\n{task.upper().replace('_', ' ')}:\")\n",
        "    print(f\"  Description: {config['description']}\")\n",
        "    \n",
        "    available_features = []\n",
        "    missing_features = []\n",
        "    \n",
        "    for feature in config['required_features']:\n",
        "        if feature in games.columns:\n",
        "            available_features.append(feature)\n",
        "        elif feature in player_stats.columns:\n",
        "            available_features.append(feature)\n",
        "        elif feature in pbp_data.columns:\n",
        "            available_features.append(feature)\n",
        "        elif feature in rosters.columns:\n",
        "            available_features.append(feature)\n",
        "        elif 'derivable_from_pbp' in config and feature in config['derivable_from_pbp']:\n",
        "            available_features.append(f\"{feature} (derivable from PBP)\")\n",
        "        else:\n",
        "            missing_features.append(feature)\n",
        "    \n",
        "    feature_availability[task] = {\n",
        "        'available': available_features,\n",
        "        'missing': missing_features,\n",
        "        'coverage': len(available_features) / len(config['required_features'])\n",
        "    }\n",
        "    \n",
        "    print(f\"  ‚úÖ Available: {available_features}\")\n",
        "    print(f\"  ‚ùå Missing: {missing_features}\")\n",
        "    print(f\"  üìä Coverage: {feature_availability[task]['coverage']:.1%}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Feature Engineering from Play-by-Play Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== FEATURE ENGINEERING FROM PBP DATA ===\n",
            "‚úÖ PBP data available: 246218 plays\n",
            "\n",
            "üéØ DERIVABLE TEAM PERFORMANCE FEATURES:\n",
            "  ‚úÖ total_yards: Sum of yards_gained by team per game\n",
            "  ‚úÖ turnovers: Sum of interceptions + fumbles lost by team per game\n",
            "  ‚úÖ time_of_possession: Sum of drive_time_of_possession by team per game\n",
            "  ‚úÖ third_down_conversion: third_down_converted / (converted + failed)\n",
            "  ‚úÖ red_zone_efficiency: TDs in red zone / red zone attempts\n",
            "  ‚úÖ total_epa: Sum of EPA by team per game\n",
            "  ‚úÖ passing_epa: EPA on passing plays only\n",
            "  ‚úÖ rushing_epa: EPA on rushing plays only\n",
            "  ‚úÖ first_downs: Sum of first_down by team per game\n",
            "  ‚úÖ penalties: Sum of penalty by team per game\n",
            "  ‚úÖ sacks: Sum of sack by team per game\n",
            "  ‚úÖ explosive_plays: Plays with yards_gained >= 20\n",
            "  ‚úÖ big_plays: Plays with yards_gained >= 40\n",
            "\n",
            "üìä SAMPLE FEATURE ENGINEERING:\n",
            "  - Team total yards: 2816 team-game records\n",
            "  - Team turnovers: 2816 team-game records\n",
            "  - Third down conversion: 2816 team-game records\n",
            "\n",
            "üöÄ CONCLUSION: All team performance features are derivable from PBP data!\n"
          ]
        }
      ],
      "source": [
        "print(\"=== FEATURE ENGINEERING FROM PBP DATA ===\")\n",
        "\n",
        "if 'pbp_data' in locals() and len(pbp_data) > 0:\n",
        "    print(f\"‚úÖ PBP data available: {len(pbp_data)} plays\")\n",
        "    \n",
        "    # Show what we can derive\n",
        "    derivable_features = {\n",
        "        'total_yards': 'Sum of yards_gained by team per game',\n",
        "        'turnovers': 'Sum of interceptions + fumbles lost by team per game',\n",
        "        'time_of_possession': 'Sum of drive_time_of_possession by team per game',\n",
        "        'third_down_conversion': 'third_down_converted / (converted + failed)',\n",
        "        'red_zone_efficiency': 'TDs in red zone / red zone attempts',\n",
        "        'total_epa': 'Sum of EPA by team per game',\n",
        "        'passing_epa': 'EPA on passing plays only',\n",
        "        'rushing_epa': 'EPA on rushing plays only',\n",
        "        'first_downs': 'Sum of first_down by team per game',\n",
        "        'penalties': 'Sum of penalty by team per game',\n",
        "        'sacks': 'Sum of sack by team per game',\n",
        "        'explosive_plays': 'Plays with yards_gained >= 20',\n",
        "        'big_plays': 'Plays with yards_gained >= 40'\n",
        "    }\n",
        "    \n",
        "    print(\"\\nüéØ DERIVABLE TEAM PERFORMANCE FEATURES:\")\n",
        "    for feature, description in derivable_features.items():\n",
        "        print(f\"  ‚úÖ {feature}: {description}\")\n",
        "    \n",
        "    # Demonstrate feature engineering\n",
        "    print(\"\\nüìä SAMPLE FEATURE ENGINEERING:\")\n",
        "    \n",
        "    # Example: Team yards per game\n",
        "    if 'yards_gained' in pbp_data.columns and 'posteam' in pbp_data.columns:\n",
        "        team_yards = pbp_data.groupby(['game_id', 'posteam'])['yards_gained'].sum().reset_index()\n",
        "        print(f\"  - Team total yards: {len(team_yards)} team-game records\")\n",
        "    \n",
        "    # Example: Team turnovers per game\n",
        "    if all(col in pbp_data.columns for col in ['interception', 'fumble_lost', 'posteam']):\n",
        "        team_turnovers = pbp_data.groupby(['game_id', 'posteam']).agg({\n",
        "            'interception': 'sum',\n",
        "            'fumble_lost': 'sum'\n",
        "        }).reset_index()\n",
        "        team_turnovers['total_turnovers'] = team_turnovers['interception'] + team_turnovers['fumble_lost']\n",
        "        print(f\"  - Team turnovers: {len(team_turnovers)} team-game records\")\n",
        "    \n",
        "    # Example: Third down conversion rate\n",
        "    if all(col in pbp_data.columns for col in ['third_down_converted', 'third_down_failed', 'down']):\n",
        "        third_down_data = pbp_data[pbp_data['down'] == 3]\n",
        "        if len(third_down_data) > 0:\n",
        "            third_down_stats = third_down_data.groupby(['game_id', 'posteam']).agg({\n",
        "                'third_down_converted': 'sum',\n",
        "                'third_down_failed': 'sum'\n",
        "            }).reset_index()\n",
        "            third_down_stats['third_down_conversion_rate'] = (\n",
        "                third_down_stats['third_down_converted'] / \n",
        "                (third_down_stats['third_down_converted'] + third_down_stats['third_down_failed'])\n",
        "            )\n",
        "            print(f\"  - Third down conversion: {len(third_down_stats)} team-game records\")\n",
        "    \n",
        "    print(f\"\\nüöÄ CONCLUSION: All team performance features are derivable from PBP data!\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚ùå PBP data not available for feature engineering demonstration\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Summary & Recommendations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== UPDATED ML READINESS ASSESSMENT ===\n",
            "\n",
            "üìä DATA HEALTH SCORE: 100.0%\n",
            "   (7/7 data sources working)\n",
            "\n",
            "ü§ñ ML READINESS (WITH FEATURE ENGINEERING):\n",
            "   Game Outcome: 100.0% coverage\n",
            "   Player Fantasy Points: 75.0% coverage\n",
            "     Missing: ['touchdowns', 'fumbles']\n",
            "   Team Performance: 100.0% coverage\n",
            "\n",
            "üìà OVERALL ML READINESS: 93.8%\n",
            "\n",
            "üéØ RECOMMENDATIONS:\n",
            "\n",
            "2. üöÄ NEXT STEPS:\n",
            "   ‚úÖ EXCELLENT data quality - ready to build ML models!\n",
            "   üìã Suggested implementation order:\n",
            "      1. üèà Player Fantasy Points Prediction (simplest, highest coverage)\n",
            "      2. üéØ Game Outcome Prediction (good coverage, high business value)\n",
            "      3. üìä Team Performance Prediction (requires PBP feature engineering)\n",
            "   üõ†Ô∏è  Feature Engineering Required:\n",
            "      - Aggregate PBP data to team-game level\n",
            "      - Join player stats with seasonal rosters for team context\n",
            "      - Create rolling averages and trend features\n"
          ]
        }
      ],
      "source": [
        "print(\"=== UPDATED ML READINESS ASSESSMENT ===\")\n",
        "print()\n",
        "\n",
        "# Overall data health score\n",
        "if 'data_availability' in locals():\n",
        "    total_sources = len(data_sources)\n",
        "    successful_sources = sum(1 for source in data_availability.values() if source['status'] == 'SUCCESS')\n",
        "    data_health_score = successful_sources / total_sources\n",
        "    \n",
        "    print(f\"üìä DATA HEALTH SCORE: {data_health_score:.1%}\")\n",
        "    print(f\"   ({successful_sources}/{total_sources} data sources working)\")\n",
        "    print()\n",
        "\n",
        "# ML readiness assessment with feature engineering\n",
        "if 'feature_availability' in locals():\n",
        "    print(\"ü§ñ ML READINESS (WITH FEATURE ENGINEERING):\")\n",
        "    \n",
        "    for task, features in feature_availability.items():\n",
        "        # Count derivable features as available\n",
        "        total_features = len(features['available']) + len(features['missing'])\n",
        "        derivable_count = sum(1 for f in features['available'] if '(derivable from PBP)' in f)\n",
        "        actual_available = len(features['available']) - derivable_count\n",
        "        actual_missing = len(features['missing']) - derivable_count\n",
        "        \n",
        "        # If we have PBP data, all derivable features are actually available\n",
        "        if 'pbp_data' in locals() and len(pbp_data) > 0:\n",
        "            if task == 'team_performance':\n",
        "                actual_missing = 0  # All team features derivable from PBP\n",
        "                actual_available = total_features\n",
        "        \n",
        "        coverage = actual_available / total_features if total_features > 0 else 0\n",
        "        \n",
        "        print(f\"   {task.replace('_', ' ').title()}: {coverage:.1%} coverage\")\n",
        "        if actual_missing > 0:\n",
        "            print(f\"     Missing: {features['missing']}\")\n",
        "    \n",
        "    avg_coverage = np.mean([\n",
        "        (len(features['available']) - sum(1 for f in features['available'] if '(derivable from PBP)' in f)) / \n",
        "        (len(features['available']) + len(features['missing']))\n",
        "        for features in feature_availability.values()\n",
        "    ])\n",
        "    \n",
        "    # Adjust for team performance if PBP available\n",
        "    if 'pbp_data' in locals() and len(pbp_data) > 0:\n",
        "        team_perf_coverage = 1.0  # All derivable from PBP\n",
        "        other_coverage = np.mean([\n",
        "            (len(features['available']) - sum(1 for f in features['available'] if '(derivable from PBP)' in f)) / \n",
        "            (len(features['available']) + len(features['missing']))\n",
        "            for task, features in feature_availability.items() if task != 'team_performance'\n",
        "        ])\n",
        "        avg_coverage = (team_perf_coverage + other_coverage) / 2\n",
        "    \n",
        "    print(f\"\\nüìà OVERALL ML READINESS: {avg_coverage:.1%}\")\n",
        "    print()\n",
        "\n",
        "# Recommendations\n",
        "print(\"üéØ RECOMMENDATIONS:\")\n",
        "print()\n",
        "\n",
        "if 'data_availability' in locals() and data_health_score < 0.8:\n",
        "    print(\"1. üîß FIX DATA SOURCES:\")\n",
        "    for source, status in data_availability.items():\n",
        "        if status['status'] == 'FAILED':\n",
        "            print(f\"   - {source}: {status['error']}\")\n",
        "    print()\n",
        "\n",
        "print(\"2. üöÄ NEXT STEPS:\")\n",
        "if 'data_availability' in locals() and 'feature_availability' in locals():\n",
        "    if data_health_score >= 0.8 and avg_coverage >= 0.8:\n",
        "        print(\"   ‚úÖ EXCELLENT data quality - ready to build ML models!\")\n",
        "        print(\"   üìã Suggested implementation order:\")\n",
        "        print(\"      1. üèà Player Fantasy Points Prediction (simplest, highest coverage)\")\n",
        "        print(\"      2. üéØ Game Outcome Prediction (good coverage, high business value)\")\n",
        "        print(\"      3. üìä Team Performance Prediction (requires PBP feature engineering)\")\n",
        "        print(\"   üõ†Ô∏è  Feature Engineering Required:\")\n",
        "        print(\"      - Aggregate PBP data to team-game level\")\n",
        "        print(\"      - Join player stats with seasonal rosters for team context\")\n",
        "        print(\"      - Create rolling averages and trend features\")\n",
        "    else:\n",
        "        print(\"   ‚ö†Ô∏è  Address data quality issues before building ML models\")\n",
        "        print(\"   üìã Suggested order:\")\n",
        "        print(\"      1. Fix failing data sources\")\n",
        "        print(\"      2. Implement feature engineering pipeline\")\n",
        "        print(\"      3. Then proceed with ML model development\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Summary & Recommendations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== SUMMARY & RECOMMENDATIONS ===\n",
            "\n",
            "üìä DATA HEALTH SCORE: 100.0%\n",
            "   (7/7 data sources working)\n",
            "\n",
            "ü§ñ ML READINESS: 91.7%\n",
            "   (Average feature coverage across prediction tasks)\n",
            "\n",
            "üéØ RECOMMENDATIONS:\n",
            "\n",
            "2. üìà IMPROVE FEATURE COVERAGE:\n",
            "   - player_fantasy_points: Missing ['touchdowns', 'fumbles']\n",
            "\n",
            "3. üöÄ NEXT STEPS:\n",
            "   ‚úÖ Data quality is good - ready to build ML models!\n",
            "   üìã Suggested order:\n",
            "      1. Start with player fantasy points prediction (simplest)\n",
            "      2. Build game outcome prediction\n",
            "      3. Add team performance prediction\n"
          ]
        }
      ],
      "source": [
        "print(\"=== SUMMARY & RECOMMENDATIONS ===\")\n",
        "print()\n",
        "\n",
        "# Overall data health score\n",
        "if 'data_availability' in locals():\n",
        "    total_sources = len(data_sources)\n",
        "    successful_sources = sum(1 for source in data_availability.values() if source['status'] == 'SUCCESS')\n",
        "    data_health_score = successful_sources / total_sources\n",
        "    \n",
        "    print(f\"üìä DATA HEALTH SCORE: {data_health_score:.1%}\")\n",
        "    print(f\"   ({successful_sources}/{total_sources} data sources working)\")\n",
        "    print()\n",
        "\n",
        "# ML readiness assessment\n",
        "if 'feature_availability' in locals():\n",
        "    avg_coverage = np.mean([task['coverage'] for task in feature_availability.values()])\n",
        "    print(f\"ü§ñ ML READINESS: {avg_coverage:.1%}\")\n",
        "    print(f\"   (Average feature coverage across prediction tasks)\")\n",
        "    print()\n",
        "\n",
        "# Recommendations\n",
        "print(\"üéØ RECOMMENDATIONS:\")\n",
        "print()\n",
        "\n",
        "if 'data_availability' in locals() and data_health_score < 0.8:\n",
        "    print(\"1. üîß FIX DATA SOURCES:\")\n",
        "    for source, status in data_availability.items():\n",
        "        if status['status'] == 'FAILED':\n",
        "            print(f\"   - {source}: {status['error']}\")\n",
        "    print()\n",
        "\n",
        "if 'feature_availability' in locals():\n",
        "    print(\"2. üìà IMPROVE FEATURE COVERAGE:\")\n",
        "    for task, features in feature_availability.items():\n",
        "        if features['coverage'] < 0.8:\n",
        "            print(f\"   - {task}: Missing {features['missing']}\")\n",
        "    print()\n",
        "\n",
        "print(\"3. üöÄ NEXT STEPS:\")\n",
        "if 'data_availability' in locals() and 'feature_availability' in locals():\n",
        "    if data_health_score >= 0.8 and avg_coverage >= 0.7:\n",
        "        print(\"   ‚úÖ Data quality is good - ready to build ML models!\")\n",
        "        print(\"   üìã Suggested order:\")\n",
        "        print(\"      1. Start with player fantasy points prediction (simplest)\")\n",
        "        print(\"      2. Build game outcome prediction\")\n",
        "        print(\"      3. Add team performance prediction\")\n",
        "    else:\n",
        "        print(\"   ‚ö†Ô∏è  Address data quality issues before building ML models\")\n",
        "        print(\"   üìã Suggested order:\")\n",
        "        print(\"      1. Fix failing data sources\")\n",
        "        print(\"      2. Identify alternative data sources for missing features\")\n",
        "        print(\"      3. Implement data quality monitoring\")\n",
        "        print(\"      4. Then proceed with ML model development\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
